import streamlit as st
import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from pypdf import PdfReader
from docx import Document
from bs4 import BeautifulSoup
from streamlit_agraph import agraph, Node, Edge, Config
import plotly.express as px
import time
from datetime import datetime
import json
import re

# ‚úÖ [THAY ƒê·ªîI] Th√™m th∆∞ vi·ªán Supabase (B·ªè gspread c≈© ƒëi ƒë·ªÉ tr√°nh l·ªói)
try:
    from supabase import create_client, Client
except ImportError:
    st.error("‚ö†Ô∏è Thi·∫øu th∆∞ vi·ªán supabase. H√£y th√™m 'supabase' v√†o requirements.txt")

# --- IMPORT C√ÅC META-BLOCKS ---
from ai_core import AI_Core
from voice_block import Voice_Engine
from prompts import DEBATE_PERSONAS, BOOK_ANALYSIS_PROMPT

# ==========================================
# ‚úÖ [TH√äM] K·∫æT N·ªêI SUPABASE
# ==========================================
has_db = False
supabase = None
try:
    SUPA_URL = st.secrets["supabase"]["url"]
    SUPA_KEY = st.secrets["supabase"]["key"]
    supabase: Client = create_client(SUPA_URL, SUPA_KEY)
    has_db = True
except: pass

# ==========================================
# üåç B·ªò T·ª™ ƒêI·ªÇN ƒêA NG√îN NG·ªÆ (GI·ªÆ NGUY√äN)
# ==========================================
TRANS = {
    "vi": {
        "lang_select": "Ng√¥n ng·ªØ / Language / ËØ≠Ë®Ä",
        "tab1": "üìö Ph√¢n T√≠ch S√°ch",
        "tab2": "‚úçÔ∏è D·ªãch Gi·∫£",
        "tab3": "üó£Ô∏è Tranh Bi·ªán",
        "tab4": "üéôÔ∏è Ph√≤ng Thu AI",
        "tab5": "‚è≥ Nh·∫≠t K√Ω",
        "t1_header": "Tr·ª£ l√Ω Nghi√™n c·ª©u & Knowledge Graph",
        "t1_up_excel": "1. K·∫øt n·ªëi Kho S√°ch (Excel)",
        "t1_up_doc": "2. T√†i li·ªáu m·ªõi (PDF/Docx)",
        "t1_btn": "üöÄ PH√ÇN T√çCH NGAY",
        "t1_analyzing": "ƒêang ph√¢n t√≠ch {name}...",
        "t1_connect_ok": "‚úÖ ƒê√£ k·∫øt n·ªëi {n} cu·ªën s√°ch.",
        "t1_graph_title": "ü™ê V≈© Tr·ª• S√°ch",
        "t2_header": "D·ªãch Thu·∫≠t ƒêa Chi·ªÅu",
        "t2_input": "Nh·∫≠p vƒÉn b·∫£n c·∫ßn d·ªãch:",
        "t2_target": "D·ªãch sang:",
        "t2_style": "Phong c√°ch:",
        "t2_btn": "‚úçÔ∏è D·ªãch Ngay",
        "t3_header": "ƒê·∫•u Tr∆∞·ªùng T∆∞ Duy",
        "t3_persona_label": "Ch·ªçn ƒê·ªëi Th·ªß:",
        "t3_input": "Nh·∫≠p ch·ªß ƒë·ªÅ tranh lu·∫≠n...",
        "t3_clear": "üóëÔ∏è X√≥a Chat",
        "t4_header": "üéôÔ∏è Ph√≤ng Thu AI ƒêa Ng√¥n Ng·ªØ",
        "t4_voice": "Ch·ªçn Gi·ªçng:",
        "t4_speed": "T·ªëc ƒë·ªô:",
        "t4_btn": "üîä T·∫†O AUDIO",
        "t5_header": "Nh·∫≠t K√Ω & L·ªãch S·ª≠",
        "t5_refresh": "üîÑ T·∫£i l·∫°i L·ªãch s·ª≠",
        "t5_empty": "Ch∆∞a c√≥ d·ªØ li·ªáu l·ªãch s·ª≠.",
    },
    "en": {
        "lang_select": "Language",
        "tab1": "üìö Book Analysis",
        "tab2": "‚úçÔ∏è Translator",
        "tab3": "üó£Ô∏è Debater",
        "tab4": "üéôÔ∏è AI Studio",
        "tab5": "‚è≥ History",
        "t1_header": "Research Assistant & Knowledge Graph",
        "t1_up_excel": "1. Connect Book Database (Excel)",
        "t1_up_doc": "2. New Documents (PDF/Docx)",
        "t1_btn": "üöÄ ANALYZE NOW",
        "t1_analyzing": "Analyzing {name}...",
        "t1_connect_ok": "‚úÖ Connected {n} books.",
        "t1_graph_title": "ü™ê Book Universe",
        "t2_header": "Multidimensional Translator",
        "t2_input": "Enter text to translate:",
        "t2_target": "Translate to:",
        "t2_style": "Style:",
        "t2_btn": "‚úçÔ∏è Translate",
        "t3_header": "Thinking Arena",
        "t3_persona_label": "Choose Opponent:",
        "t3_input": "Enter debate topic...",
        "t3_clear": "üóëÔ∏è Clear Chat",
        "t4_header": "üéôÔ∏è Multilingual AI Studio",
        "t4_voice": "Select Voice:",
        "t4_speed": "Speed:",
        "t4_btn": "üîä GENERATE AUDIO",
        "t5_header": "Logs & History",
        "t5_refresh": "üîÑ Refresh History",
        "t5_empty": "No history data found.",
    },
    "zh": {
        "lang_select": "ËØ≠Ë®Ä",
        "tab1": "üìö ‰π¶Á±çÂàÜÊûê",
        "tab2": "‚úçÔ∏è ÁøªËØë‰∏ìÂÆ∂",
        "tab3": "üó£Ô∏è Ëæ©ËÆ∫Âú∫",
        "tab4": "üéôÔ∏è AI ÂΩïÈü≥ÂÆ§",
        "tab5": "‚è≥ ÂéÜÂè≤ËÆ∞ÂΩï",
        "t1_header": "Á†îÁ©∂Âä©Êâã & Áü•ËØÜÂõæË∞±",
        "t1_up_excel": "1. ËøûÊé•‰π¶Â∫ì (Excel)",
        "t1_up_doc": "2. ‰∏ä‰º†Êñ∞ÊñáÊ°£ (PDF/Docx)",
        "t1_btn": "üöÄ Á´ãÂç≥ÂàÜÊûê",
        "t1_analyzing": "Ê≠£Âú®ÂàÜÊûê {name}...",
        "t1_connect_ok": "‚úÖ Â∑≤ËøûÊé• {n} Êú¨‰π¶„ÄÇ",
        "t1_graph_title": "ü™ê ‰π¶Á±çÂÆáÂÆô",
        "t2_header": "Â§öÁª¥ÁøªËØë",
        "t2_input": "ËæìÂÖ•ÊñáÊú¨:",
        "t2_target": "ÁøªËØëÊàê:",
        "t2_style": "È£éÊ†º:",
        "t2_btn": "‚úçÔ∏è ÁøªËØë",
        "t3_header": "ÊÄùÁª¥Á´ûÊäÄÂú∫",
        "t3_persona_label": "ÈÄâÊã©ÂØπÊâã:",
        "t3_input": "ËæìÂÖ•Ëæ©ËÆ∫‰∏ªÈ¢ò...",
        "t3_clear": "üóëÔ∏è Ê∏ÖÈô§ËÅäÂ§©",
        "t4_header": "üéôÔ∏è AI Â§öËØ≠Ë®ÄÂΩïÈü≥ÂÆ§",
        "t4_voice": "ÈÄâÊã©Â£∞Èü≥:",
        "t4_speed": "ËØ≠ÈÄü:",
        "t4_btn": "üîä ÁîüÊàêÈü≥È¢ë",
        "t5_header": "Êó•Âøó & ÂéÜÂè≤",
        "t5_refresh": "üîÑ Âà∑Êñ∞ÂéÜÂè≤",
        "t5_empty": "ÊöÇÊó†ÂéÜÂè≤Êï∞ÊçÆ„ÄÇ",
    }
}

# H√†m l·∫•y text theo ng√¥n ng·ªØ
def T(key):
    lang = st.session_state.get('weaver_lang', 'vi')
    return TRANS.get(lang, TRANS['vi']).get(key, key)

# --- C√ÅC H√ÄM PH·ª§ TR·ª¢ (GI·ªÆ NGUY√äN) ---
@st.cache_resource
def load_models():
    try:
        model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2", device='cpu')
        model.max_seq_length = 128
        return model
    except Exception as e:
        return None

def check_model_available():
    model = load_models()
    return model is not None

def doc_file(uploaded_file):
    if not uploaded_file: return ""
    ext = uploaded_file.name.split('.')[-1].lower()
    try:
        if ext == "pdf":
            reader = PdfReader(uploaded_file)
            return "\n".join([page.extract_text() for page in reader.pages])
        elif ext == "docx":
            doc = Document(uploaded_file)
            return "\n".join([p.text for p in doc.paragraphs])
        elif ext in ["txt", "md", "html"]:
            return str(uploaded_file.read(), "utf-8")
    except: return ""
    return ""

# ‚úÖ [S·ª¨A] H√ÄM L∆ØU L·ªäCH S·ª¨ (D√πng Supabase thay GSheet)
def luu_lich_su(loai, tieu_de, noi_dung):
    if not has_db: return
    user = st.session_state.get("current_user", "Unknown")
    data = {
        "type": loai,
        "title": tieu_de,
        "content": noi_dung,
        "user_name": user,
        "sentiment_score": 0.0,
        "sentiment_label": "Neutral"
    }
    try:
        # D√πng t√™n b·∫£ng ch√≠nh x√°c: History_Logs
        supabase.table("History_Logs").insert(data).execute()
    except Exception as e:
        print(f"L·ªói l∆∞u: {e}")

# ‚úÖ [S·ª¨A] H√ÄM T·∫¢I L·ªäCH S·ª¨ (Map v·ªÅ format c≈©)
def tai_lich_su():
    if not has_db: return []
    try:
        response = supabase.table("History_Logs").select("*").order("created_at", desc=True).limit(50).execute()
        formatted = []
        for item in response.data:
            t = item.get("created_at", "").replace("T", " ")[:19]
            formatted.append({
                "Time": t,
                "Type": item.get("type"),
                "Title": item.get("title"),
                "Content": item.get("content"),
                "User": item.get("user_name"),
                "SentimentScore": item.get("sentiment_score", 0),
                "SentimentLabel": item.get("sentiment_label", "Neutral")
            })
        return formatted
    except: return []

# --- H√ÄM CH√çNH: RUN() ---
def run():
    ai = AI_Core()
    voice = Voice_Engine()
    
    with st.sidebar:
        st.markdown("---")
        lang_choice = st.selectbox("üåê " + TRANS['vi']['lang_select'], ["Ti·∫øng Vi·ªát", "English", "‰∏≠Êñá"], key="weaver_lang_selector")
        if lang_choice == "Ti·∫øng Vi·ªát": st.session_state.weaver_lang = 'vi'
        elif lang_choice == "English": st.session_state.weaver_lang = 'en'
        else: st.session_state.weaver_lang = 'zh'
    
    st.header(f"üß† The Cognitive Weaver")
    
    tab1, tab2, tab3, tab4, tab5 = st.tabs([T("tab1"), T("tab2"), T("tab3"), T("tab4"), T("tab5")])

    # === TAB 1: RAG & GRAPH ===
    with tab1:
        st.subheader(T("t1_header"))
        c1, c2, c3 = st.columns([1, 1, 1])
        with c1: file_excel = st.file_uploader(T("t1_up_excel"), type="xlsx", key="w_t1_ex")
        with c2: uploaded_files = st.file_uploader(T("t1_up_doc"), type=["pdf", "docx", "txt"], accept_multiple_files=True, key="w_t1_doc")
        with c3: 
            st.write(""); st.write("")
            btn_run = st.button(T("t1_btn"), type="primary", use_container_width=True)

        if btn_run and uploaded_files:
            # Progress bar
            total = len(uploaded_files)
            p_bar = st.progress(0)
            status = st.empty()
            
            vec = load_models()
            db, df = None, None
            has_rag = False
            
            if file_excel:
                try:
                    df = pd.read_excel(file_excel).dropna(subset=["T√™n s√°ch"])
                    db = vec.encode([f"{r['T√™n s√°ch']} {str(r.get('C·∫¢M NH·∫¨N',''))}" for _, r in df.iterrows()])
                    has_rag = True
                    st.success(T("t1_connect_ok").format(n=len(df)))
                except: st.error("L·ªói Excel.")

            for idx, f in enumerate(uploaded_files):
                status.text(f"ƒêang x·ª≠ l√Ω: {f.name}")
                p_bar.progress(idx / total)
                
                text = doc_file(f)
                link = ""
                if has_rag and vec:
                    q = vec.encode([text[:2000]])
                    sc = cosine_similarity(q, db)[0]
                    sim_idx = np.argsort(sc)[::-1][:3]
                    for i in sim_idx:
                        if sc[i] > 0.35: link += f"- {df.iloc[i]['T√™n s√°ch']} ({sc[i]*100:.0f}%)\n"

                with st.spinner(T("t1_analyzing").format(name=f.name)):
                    prompt = f"Ph√¢n t√≠ch t√†i li·ªáu '{f.name}'. Li√™n quan: {link}\nN·ªôi dung: {text[:30000]}"
                    res = ai.analyze_static(prompt, BOOK_ANALYSIS_PROMPT)
                    
                    st.markdown(f"### üìÑ {f.name}")
                    st.markdown(res)
                    st.markdown("---")
                    luu_lich_su("Ph√¢n T√≠ch S√°ch", f.name, res[:200])
                
                # ‚úÖ [TH√äM] UPLOAD FILE L√äN SUPABASE
                if has_db:
                    try:
                        f.seek(0)
                        file_bytes = f.read()
                        path = f"{datetime.now().strftime('%Y_%m_%d')}/{f.name}"
                        supabase.storage.from_("book_files").upload(path, file_bytes, {"content-type": f.type, "x-upsert": "true"})
                        st.toast(f"üíæ ƒê√£ l∆∞u file {f.name}", icon="‚òÅÔ∏è")
                    except: pass
                
                p_bar.progress((idx + 1) / total)
            status.text("‚úÖ Ho√†n th√†nh!")

        # Graph (Gi·ªØ nguy√™n)
        if file_excel:
            try:
                with st.expander(T("t1_graph_title"), expanded=False):
                    vec = load_models()
                    if "book_embs" not in st.session_state: st.session_state.book_embs = vec.encode(df["T√™n s√°ch"].tolist())
                    embs = st.session_state.book_embs
                    sim = cosine_similarity(embs)
                    nodes, edges = []; max_nodes = st.slider("Max Nodes:", 5, len(df), min(50, len(df))); threshold = st.slider("Threshold:", 0.0, 1.0, 0.45)
                    for i in range(max_nodes):
                        nodes.append(Node(id=str(i), label=df.iloc[i]["T√™n s√°ch"], size=20, color="#FFD166"))
                        for j in range(i+1, max_nodes):
                            if sim[i,j]>threshold: edges.append(Edge(source=str(i), target=str(j), color="#118AB2"))
                    agraph(nodes, edges, Config(width=900, height=600, directed=False, physics=True, collapsible=False))
            except: pass

    # === TAB 2: D·ªäCH GI·∫¢ (GI·ªÆ NGUY√äN) ===
    with tab2:
        st.subheader(T("t2_header"))
        txt = st.text_area(T("t2_input"), height=150, key="w_t2_inp")
        c_l, c_s, c_b = st.columns([1,1,1])
        with c_l: target_lang = st.selectbox(T("t2_target"), ["Ti·∫øng Vi·ªát", "English", "Chinese", "French", "Japanese"], key="w_t2_lang")
        with c_s: style = st.selectbox(T("t2_style"), ["Default", "Academic", "Literary", "Business"], key="w_t2_style")
        if st.button(T("t2_btn"), key="w_t2_btn") and txt:
            with st.spinner("..."):
                p = f"Translate to {target_lang}. Style: {style}. Text: {txt}"
                res = ai.generate(p, model_type="pro")
                st.markdown(res)
                luu_lich_su("D·ªãch Thu·∫≠t", f"{target_lang}", txt[:50])

    # === TAB 3: ƒê·∫§U TR∆Ø·ªúNG (GI·ªÆ NGUY√äN) ===
    with tab3:
        st.subheader(T("t3_header"))
        mode = st.radio("Mode:", ["üë§ Solo", "‚öîÔ∏è Multi-Agent"], horizontal=True, key="w_t3_mode")
        if "weaver_chat" not in st.session_state: st.session_state.weaver_chat = []

        if mode == "üë§ Solo":
            c1, c2 = st.columns([3, 1])
            with c1: persona = st.selectbox(T("t3_persona_label"), list(DEBATE_PERSONAS.keys()), key="w_t3_solo_p")
            with c2: 
                if st.button(T("t3_clear"), key="w_t3_clr"): st.session_state.weaver_chat = []; st.rerun()
            for msg in st.session_state.weaver_chat: st.chat_message(msg["role"]).write(msg["content"])
            if prompt := st.chat_input(T("t3_input")):
                st.chat_message("user").write(prompt)
                st.session_state.weaver_chat.append({"role": "user", "content": prompt})
                recent = st.session_state.weaver_chat[-10:]
                ctx = "\n".join([f"{m['role']}: {m['content']}" for m in recent])
                with st.chat_message("assistant"):
                    res = ai.generate(f"History:\n{ctx}\nUser: {prompt}", model_type="flash", system_instruction=DEBATE_PERSONAS[persona])
                    if res:
                        st.write(res)
                        st.session_state.weaver_chat.append({"role": "assistant", "content": res})
                        luu_lich_su("Tranh Bi·ªán Solo", f"{persona}...", f"Q:{prompt}\nA:{res}")
        else:
            parts = st.multiselect("Ch·ªçn H·ªôi ƒê·ªìng:", list(DEBATE_PERSONAS.keys()), default=[list(DEBATE_PERSONAS.keys())[0], list(DEBATE_PERSONAS.keys())[1]], max_selections=3)
            topic = st.text_input("Ch·ªß ƒë·ªÅ:", key="w_t3_topic")
            if st.button("üî• KHAI CHI·∫æN", disabled=(len(parts)<2 or not topic)):
                st.session_state.weaver_chat = []
                st.info(f"Ch·ªß ƒë·ªÅ: {topic}")
                full_log = []
                with st.status("üî• ƒêang ƒë·∫•u...") as status:
                    for rnd in range(1, 4):
                        for p in parts:
                            try:
                                res = ai.generate(f"Ch·ªß ƒë·ªÅ: {topic}. V√≤ng {rnd}. Ph·∫£n bi·ªán.", model_type="flash", system_instruction=DEBATE_PERSONAS[p])
                                if res:
                                    st.write(f"**{p}:** {res}")
                                    full_log.append(f"{p}: {res}")
                                    time.sleep(2)
                            except: pass
                    status.update(label="Xong!", state="complete")
                luu_lich_su("H·ªôi ƒê·ªìng", topic, "\n".join(full_log))

    # === TAB 4: PH√íNG THU (GI·ªÆ NGUY√äN) ===
    with tab4:
        st.subheader(T("t4_header"))
        inp = st.text_area("Text:", height=200); btn = st.button(T("t4_btn"))
        if btn and inp:
            path = voice.speak(inp)
            if path: st.audio(path)

    # === TAB 5: NH·∫¨T K√ù (GI·ªÆ NGUY√äN + TOOL CHUY·ªÇN D·ªÆ LI·ªÜU) ===
    with tab5:
        st.subheader("‚è≥ Nh·∫≠t K√Ω")
        if st.button("üîÑ T·∫£i l·∫°i"): st.session_state.history_cloud = tai_lich_su(); st.rerun()
        
        data = st.session_state.get("history_cloud", tai_lich_su())
        if data:
            df_h = pd.DataFrame(data)
            if "SentimentScore" in df_h.columns:
                try:
                    df_h["score"] = pd.to_numeric(df_h["SentimentScore"], errors='coerce').fillna(0)
                    st.plotly_chart(px.line(df_h, x="Time", y="score", markers=True), use_container_width=True)
                except: pass
            
            for _, item in df_h.iterrows():
                with st.expander(f"{item['Time']} | {item['Type']} | {item['Title']}"):
                    st.markdown(item['Content'])
        else: st.info("Tr·ªëng.")

        # ‚úÖ [TH√äM] TOOL CHUY·ªÇN D·ªÆ LI·ªÜU V4 (FIX L·ªñI D·∫§U PH·∫®Y & T√äN B·∫¢NG)
        st.divider()
        with st.expander("üõ†Ô∏è C√îNG C·ª§ CHUY·ªÇN NH√Ä (V4 - Final)", expanded=True):
            upl = st.file_uploader("Upload CSV c≈©:", type=["csv"])
            if upl and st.button("üöÄ CHUY·ªÇN D·ªÆ LI·ªÜU"):
                df_old = pd.read_csv(upl); df_old.columns = df_old.columns.str.strip()
                bar = st.progress(0); succ = 0; err = 0; logs = []
                for i, row in df_old.iterrows():
                    try:
                        # Fix ng√†y
                        raw_t = str(row.get('Time', '')).strip()
                        clean_t = datetime.now().isoformat()
                        if raw_t and raw_t.lower() != 'nan':
                            try: clean_t = pd.to_datetime(raw_t).strftime('%Y-%m-%d %H:%M:%S')
                            except: pass
                        # Fix s·ªë 0,95 -> 0.95
                        raw_s = str(row.get('SentimentScore', '0')).replace(',', '.')
                        try: final_s = float(raw_s)
                        except: final_s = 0.0
                        
                        data = {
                            "created_at": clean_t,
                            "type": str(row.get('Type', 'General')),
                            "title": str(row.get('Title', 'No Title')),
                            "content": str(row.get('Content', '')),
                            "user_name": str(row.get('User', 'Imported')),
                            "sentiment_score": final_s,
                            "sentiment_label": str(row.get('SentimentLabel', 'Neutral'))
                        }
                        # Fix t√™n b·∫£ng Hoa
                        supabase.table("History_Logs").insert(data).execute()
                        succ += 1
                    except Exception as e: err += 1; logs.append(str(e))
                    bar.progress((i+1)/len(df_old))
                
                st.success(f"Xong: {succ} d√≤ng."); 
                if err: st.error(f"L·ªói: {err}"); st.write(logs)
                time.sleep(1); st.rerun()
